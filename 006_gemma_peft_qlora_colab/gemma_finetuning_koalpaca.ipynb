{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nODwmF0MEOQb"
      },
      "source": [
        "# Instruction Finetuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BGrlf29Eowf"
      },
      "source": [
        "### 데이터셋 구축\n",
        "\n",
        "1. 목적 정의: 먼저, 세부 튜닝을 통해 달성하고자 하는 목표를 명확히 합니다.\n",
        "1. 데이터 수집: 목표에 맞는 데이터를 수집합니다. 이 데이터는 공개 데이터셋일 수도 있고, 사용자가 직접 수집한 데이터일 수도 있습니다.\n",
        "\n",
        "1. 데이터 가공: 수집한 데이터를 모델 훈련에 적합하게 가공합니다. 이 과정에서는 데이터를 정제하고, 필요한 형식으로 변환하는 작업이 포함됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9r0smmEIAjT"
      },
      "source": [
        "### 공개 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ilVIo8M0IE1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets==2.17.0 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (2.17.0)\n",
            "Requirement already satisfied: filelock in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (3.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (4.66.4)\n",
            "Requirement already satisfied: xxhash in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.17.0) (2023.10.0)\n",
            "Requirement already satisfied: aiohttp in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (0.23.4)\n",
            "Requirement already satisfied: packaging in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from datasets==2.17.0) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from aiohttp->datasets==2.17.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from aiohttp->datasets==2.17.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from aiohttp->datasets==2.17.0) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets==2.17.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (2024.2.2)\n",
            "Requirement already satisfied: colorama in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from tqdm>=4.62.1->datasets==2.17.0) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from pandas->datasets==2.17.0) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from pandas->datasets==2.17.0) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from pandas->datasets==2.17.0) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.17.0) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets==2.17.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_Sg9dv0QIWWR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\28006030\\.conda\\envs\\tfm_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['instruction', 'input', 'output', 'text'],\n",
            "        num_rows: 49620\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# 데이터셋 로드\n",
        "dataset = load_dataset(\"royboy0416/ko-alpaca\")\n",
        "\n",
        "# 데이터셋의 구조 확인\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o1basYqSJFys"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': '건강을 유지하기 위한 세 가지 팁을 알려주세요.',\n",
              " 'input': '',\n",
              " 'output': '세 가지 팁은 아침식사를 꼭 챙기며, 충분한 수면을 취하고, 적극적으로 운동을 하는 것입니다.',\n",
              " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request. \\n\\n### Instruction:\\n건강을 유지하기 위한 세 가지 팁을 알려주세요.\\n\\n### Response:\\n세 가지 팁은 아침식사를 꼭 챙기며, 충분한 수면을 취하고, 적극적으로 운동을 하는 것입니다.'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaQbtRTTovBm"
      },
      "source": [
        "# Alpaca 데이터셋 포맷팅\n",
        "```\n",
        "{'instruction': '건강을 유지하기 위한 세 가지 팁을 알려주세요.',\n",
        " 'input': '',\n",
        " 'output': '세 가지 팁은 아침식사를 꼭 챙기며, 충분한 수면을 취하고, 적극적으로 운동을 하는 것입니다.',\n",
        " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request. \\n\\n### Instruction:\\n건강을 유지하기 위한 세 가지 팁을 알려주세요.\\n\\n### Response:\\n세 가지 팁은 아침식사를 꼭 챙기며, 충분한 수면을 취하고, 적극적으로 운동을 하는 것입니다.'}\n",
        "```\n",
        "\n",
        "# Gemma 데이터셋 포맷팅\n",
        "\n",
        "```<start_of_turn>user```<br>\n",
        "```What is Cramer's Rule?<end_of_turn>```<br>\n",
        "```<start_of_turn>model```<br>\n",
        "```Cramer's Rule is ...<end_of_turn>```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mMh65FNUKIir"
      },
      "outputs": [],
      "source": [
        "# 'prompt' 필드 생성 함수\n",
        "def format_instruction(example):\n",
        "\n",
        "    # 추가 컨텍스트(input 필드)가 있는 경우\n",
        "    if example['input'] and len(example['input']) > 0:\n",
        "        text = f\"\"\"<start_of_turn>user\\n{example[\"instruction\"]}\\n{example[\"input\"]}<end_of_turn>\\n<start_of_turn>model\\n{example[\"output\"]}<end_of_turn>\"\"\"\n",
        "    # input 필드가 없는 경우\n",
        "    else:\n",
        "        text = f\"\"\"<start_of_turn>user\\n{example[\"instruction\"]}<end_of_turn>\\n<start_of_turn>model\\n{example[\"output\"]}<end_of_turn>\"\"\"\n",
        "\n",
        "    return {'prompt': text}\n",
        "\n",
        "# 데이터셋의 prompt 필드를 업데이트\n",
        "dataset = dataset.map(format_instruction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fs2nTvjMteR9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': '건강을 유지하기 위한 세 가지 팁을 알려주세요.',\n",
              " 'input': '',\n",
              " 'output': '세 가지 팁은 아침식사를 꼭 챙기며, 충분한 수면을 취하고, 적극적으로 운동을 하는 것입니다.',\n",
              " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request. \\n\\n### Instruction:\\n건강을 유지하기 위한 세 가지 팁을 알려주세요.\\n\\n### Response:\\n세 가지 팁은 아침식사를 꼭 챙기며, 충분한 수면을 취하고, 적극적으로 운동을 하는 것입니다.',\n",
              " 'prompt': '<start_of_turn>user\\n건강을 유지하기 위한 세 가지 팁을 알려주세요.<end_of_turn>\\n<start_of_turn>model\\n세 가지 팁은 아침식사를 꼭 챙기며, 충분한 수면을 취하고, 적극적으로 운동을 하는 것입니다.<end_of_turn>'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YOh_8dkHYPMr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': '홀수 중 하나를 밝히세요.',\n",
              " 'input': '트위터, 인스타그램, 텔레그램',\n",
              " 'output': '텔레그램입니다.',\n",
              " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request. \\n\\n### Instruction:\\n홀수 중 하나를 밝히세요.\\n\\n### Input:\\n트위터, 인스타그램, 텔레그램\\n\\n### Response:\\n텔레그램입니다.',\n",
              " 'prompt': '<start_of_turn>user\\n홀수 중 하나를 밝히세요.\\n트위터, 인스타그램, 텔레그램<end_of_turn>\\n<start_of_turn>model\\n텔레그램입니다.<end_of_turn>'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['train'][5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtExQUBlEFMv"
      },
      "source": [
        "### 모델 로드 및 튜닝:\n",
        "\n",
        "1. 모델 학습: gemma-2b 모델을 로드하고, 준비된 데이터셋을 사용하여 모델을 세부 튜닝합니다. 이 과정에서는 학습률, 에폭 수 등의 파라미터를 조정할 수 있습니다.\n",
        "1. 평가 및 반복: 튜닝된 모델을 평가하고 결과를 확인합니다. 필요에 따라 여러 번 반복하여 모델의 성능을 최적화할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XrefsFXqFM9V"
      },
      "outputs": [],
      "source": [
        "!pip install -qU transformers==4.38.0 accelerate==0.27.1 bitsandbytes==0.42.0 peft==0.8.2 trl==0.7.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -qU ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple/\n",
            "Requirement already satisfied: bitsandbytes in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (0.42.0)\n",
            "Requirement already satisfied: scipy in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in d:\\condaenvs\\.conda\\envs\\tfm_env\\lib\\site-packages (from scipy->bitsandbytes) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install -i https://pypi.org/simple/ bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rd1Ya28FujGg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jun 16 00:20:49 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 555.99                 Driver Version: 555.99         CUDA Version: 12.5     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3060      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
            "|  0%   39C    P8             19W /  170W |    1465MiB /  12288MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      2316    C+G   ...on\\125.0.2535.92\\msedgewebview2.exe      N/A      |\n",
            "|    0   N/A  N/A      4004    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
            "|    0   N/A  N/A      6216    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
            "|    0   N/A  N/A      7576    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
            "|    0   N/A  N/A      8380    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
            "|    0   N/A  N/A      8496    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
            "|    0   N/A  N/A      9336    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
            "|    0   N/A  N/A      9804    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A     10676    C+G   ...AppData\\Local\\Obsidian\\Obsidian.exe      N/A      |\n",
            "|    0   N/A  N/A     11532    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
            "|    0   N/A  N/A     12304    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
            "|    0   N/A  N/A     13720    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A     15064    C+G   ...05.0_x64__8wekyb3d8bbwe\\Cortana.exe      N/A      |\n",
            "|    0   N/A  N/A     18260      C   ...ta\\Local\\Programs\\Ollama\\ollama.exe      N/A      |\n",
            "|    0   N/A  N/A     19708    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
            "|    0   N/A  N/A     22336    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
            "|    0   N/A  N/A     64400    C+G   ...ogramData\\VSCode-win32-x64\\Code.exe      N/A      |\n",
            "|    0   N/A  N/A     69052    C+G   ...e Stream\\92.0.0.0\\GoogleDriveFS.exe      N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jRjOEOq9JBju"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import json\n",
        "import time\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from huggingface_hub import notebook_login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9Cn_f9eewOs0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de10385e80864b4c91a1b8f3f831fdb7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bZ87WNIPJZLN"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 13\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#ImportError: Using bitsandbytes 8-bit quantization requires Accelerate: pip install accelerate and the latest version of bitsandbytes: pip install -i https://pypi.org/simple/ bitsandbytes\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# bnb_config = BitsAndBytesConfig(load_in_4bit=True,\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#                                 bnb_4bit_quant_type=\"nf4\",\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#                                 bnb_4bit_compute_dtype=torch.bfloat16)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[0;32m      8\u001b[0m     load_in_8bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m     bnb_8bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf8\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# NF8 quantization\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     bnb_8bit_compute_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16  \u001b[38;5;66;03m# bfloat16 for computation\u001b[39;00m\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id, add_eos_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\28006030\\.conda\\envs\\tfm_env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    562\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    563\u001b[0m     )\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    567\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\28006030\\.conda\\envs\\tfm_env\\lib\\site-packages\\transformers\\modeling_utils.py:3024\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\n\u001b[0;32m   3026\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3027\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[0;32m   3028\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
            "File \u001b[1;32mc:\\Users\\28006030\\.conda\\envs\\tfm_env\\lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_8bit.py:62\u001b[0m, in \u001b[0;36mBnb8BitHfQuantizer.validate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_environment\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[1;32m---> 62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m         )\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_flax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sure the weights are in PyTorch format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         )\n",
            "\u001b[1;31mImportError\u001b[0m: Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`"
          ]
        }
      ],
      "source": [
        "model_id = \"google/gemma-2b\"\n",
        "\n",
        "#ImportError: Using bitsandbytes 8-bit quantization requires Accelerate: pip install accelerate and the latest version of bitsandbytes: pip install -i https://pypi.org/simple/ bitsandbytes\n",
        "# bnb_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "#                                 bnb_4bit_quant_type=\"nf4\",\n",
        "#                                 bnb_4bit_compute_dtype=torch.bfloat16)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    bnb_8bit_quant_type=\"nf8\",  # NF8 quantization\n",
        "    bnb_8bit_compute_dtype=torch.bfloat16  # bfloat16 for computation\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
        "                                             quantization_config=bnb_config,\n",
        "                                             device_map={\"\":0})\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN96zjNf7O25"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPJn3dPwwBll"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)\n",
        "dataset = dataset['train'].train_test_split(test_size=0.2)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRAQtIgVxfG6"
      },
      "outputs": [],
      "source": [
        "train_data = dataset[\"train\"]\n",
        "test_data = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJLdkGrnxmXQ"
      },
      "outputs": [],
      "source": [
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO4pjPKdxny-"
      },
      "outputs": [],
      "source": [
        "def get_completion(query: str, model, tokenizer):\n",
        "\n",
        "  prompt_template = \"\"\"<start_of_turn>user\n",
        "  {query}\n",
        "  <end_of_turn>\n",
        "  <start_of_turn>model\n",
        "  \"\"\"\n",
        "  prompt = prompt_template.format(query=query)\n",
        "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
        "  model_inputs = encodeds.to(\"cuda:0\")\n",
        "  generated_ids = model.generate(**model_inputs, max_new_tokens=256)\n",
        "  decoded = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "  return decoded\n",
        "\n",
        "# Fine tuning 이전\n",
        "result = get_completion(query=\"건강을 유지하기 위한 세 가지 팁을 알려주세요.\", model=model, tokenizer=tokenizer)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTmSRl0Fz4KY"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    target_modules=['o_proj', 'q_proj', 'up_proj', 'v_proj', 'k_proj', 'down_proj', 'gate_proj'],\n",
        "    lora_dropout=0.05,\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        "    dataset_text_field=\"prompt\",\n",
        "    peft_config=lora_config,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=10,\n",
        "        max_steps=100,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=10,\n",
        "        output_dir=\"outputs\",\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "    ),\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeygbIZg24Y_"
      },
      "outputs": [],
      "source": [
        "# Fine tuning 이후\n",
        "result = get_completion(query=\"건강을 유지하기 위한 세 가지 팁을 알려주세요.\",\n",
        "                        model=trainer.model,\n",
        "                        tokenizer=tokenizer)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09pIPcLpBuAP"
      },
      "outputs": [],
      "source": [
        "# Fine tuning 이후\n",
        "result = get_completion(query=\"불면증을 해결하는 방법을 세 가지 알려주세요.\",\n",
        "                        model=trainer.model,\n",
        "                        tokenizer=tokenizer)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH9FFSWS2uue"
      },
      "source": [
        "# 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLGaVpqY2n7a"
      },
      "outputs": [],
      "source": [
        "new_model = \"gemma-2b-it-koalpaca-finetuned\"\n",
        "trainer.model.save_pretrained(new_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
